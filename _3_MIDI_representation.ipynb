{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GMxHjJKW7B0"
      },
      "source": [
        "# MIDI Representations and AI\n",
        "\n",
        "Computer-generated MIDI has been a goal ever since the protocol was invented in 1983. The first MIDI sequencer was created in 1984 and the first MIDI composition was created in 1985. Sequential modeling has also come a long way since then. In order to investigate sequential models with MIDI, we'll focus on MIDI file representations, how it works and talk about input formats for some AI models that attempt to generate MIDI compositions. In subsequent posts we will build toward training our own sequential model to generate MIDI compositions (something akin to some of the models provided by [Magenta Studio](https://magenta.tensorflow.org/studio/))\n",
        "\n",
        "As musicians working within a digital audio workstation (DAW) like [Ableton Live](https://www.ableton.com/en/live/), FL Studio, Garageband, Sony Acid or Logic Pro, we often work with audio and MIDI tracks together. MIDI files are represented as discrete tones in a spectrum, onto which a sound is attached to each note. We can represent percussion, melodies and everything in between with these notes. MIDI has also been one of the first places where automation and music generation made its mark. First, let's walk through what a MIDI file looks like. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MIDI File Breakdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is a MIDI file anyways? It is a binary file that contains a sequence of MIDI messages. MIDI messages are instructions that tell a MIDI device (like a synthesizer) what to do. MIDI messages can be things like \"play this note at this volume\" or \"change the pitch bend to this value\". MIDI files are made up a header and a body. The header contains meta information and the body contains the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our exploration, we'll use an example MIDI file representing the monophonic chorus of the song \"Roja\" by \"A.R. Rahman\" as an example. The MIDI file is from the TheoryTab dataset (and IMO is not a great rendition of the original song but hopefully good enough to recognize and to explore MIDI files :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the MIDI file from Github and save it in the current directory\n",
        "\n",
        "# wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O FILENAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup the path variable for later use\n",
        "local_datapath_midi = 'test-data/roja-ar-rahman-melody.mid'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what the raw binary file looks like when we open it in VSCode...here's what the first few messages in the file. \n",
        "\n",
        "```MThd\u0000\u0000\u0000\u0006\u0000\u0001\u0000\u0002\u0001�MTrk\u0000\u0000\u0002!\u0000�Q\u0003\t�\u001b\u0000�X\u0004\u0004\u0002\u0018\b\u0000�Y\u0002\u0004\u0000\u0000�\u0006\b4_4_m_5_�@�\u0006\t11_11__5_�@�\u0006\b4_4_m_5_�@�\u0006\t11_11__5_�@�\u0006\u00074_4__5_�@�\u0006\u00079_9__5_�@�\u0006```\n",
        "\n",
        "Needless to say, these are gibberish to us and it isn't important to understand the byte encodings to use it (though if you're interested in the format and byte representations more info here: https://www.cs.cmu.edu/~music/cmsip/readings/MIDI%20tutorial%20for%20programmers.html or http://www.music.mcgill.ca/~ich/classes/mumt306/StandardMIDIfileformat.html#BM2_2). \n",
        "\n",
        "For us, we just need to know that MIDI files are split into headers and tracks. The header contain the file format, ticks per beat and the number of tracks. The file format is either 0, 1 or 2. Format 0 means that there is only one track. Format 1 means that there are multiple tracks. Format 2 means that there are multiple tracks but that each track is independent of the others. The tracks contain the MIDI events (aka messages) - musical events and meta events.\n",
        "\n",
        "Let's use a library to parse the MIDI file and see what the file contents look like section-by-section. The [Mido](https://mido.readthedocs.io/en/latest/) library does a great job parsing the MIDI messages while maintaining the message structure, so we'll start there. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN9DcVeMYNqG",
        "outputId": "ffbbfd87-5a1b-4d0a-8827-0abfc3ee6f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mido in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (1.3.0)\n",
            "Requirement already satisfied: packaging~=23.1 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from mido) (23.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install mido\n",
        "from mido import MidiFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gyhsNcyQWycG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MidiFile(type=1, ticks_per_beat=480, tracks=[\n",
            "  MidiTrack([\n",
            "    MetaMessage('set_tempo', tempo=631579, time=0),\n",
            "    MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0),\n",
            "    MetaMessage('key_signature', key='E', time=0),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=0),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=960),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4__5_', time=960),\n",
            "    MetaMessage('marker', text='9_9__5_', time=960),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=1920),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=960),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=960),\n",
            "    MetaMessage('marker', text='9_9__5_', time=960),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4__5_', time=1920),\n",
            "    MetaMessage('marker', text='9_9__5_', time=480),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=480),\n",
            "    MetaMessage('marker', text='11_11__5_', time=360),\n",
            "    MetaMessage('marker', text='4_4__5_', time=600),\n",
            "    MetaMessage('marker', text='9_9__5_', time=480),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=480),\n",
            "    MetaMessage('marker', text='11_11__5_', time=360),\n",
            "    MetaMessage('marker', text='4_4__5_', time=600),\n",
            "    MetaMessage('marker', text='9_9__5_', time=480),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=480),\n",
            "    MetaMessage('marker', text='11_11__5_', time=360),\n",
            "    MetaMessage('marker', text='4_4__5_', time=600),\n",
            "    MetaMessage('marker', text='9_9__5_', time=480),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=480),\n",
            "    MetaMessage('marker', text='11_11__5_', time=360),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=600),\n",
            "    MetaMessage('marker', text='9_9_m_7_', time=960),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=1920),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4_m_5_', time=960),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('marker', text='4_4__5_', time=960),\n",
            "    MetaMessage('marker', text='9_9__5_', time=960),\n",
            "    MetaMessage('marker', text='11_11__5_', time=960),\n",
            "    MetaMessage('end_of_track', time=1)]),\n",
            "  MidiTrack([\n",
            "    MetaMessage('track_name', name='melody', time=0),\n",
            "    Message('program_change', channel=0, program=0, time=0),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=71, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=360),\n",
            "    Message('note_on', channel=0, note=71, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=120),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=960),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=360),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=120),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=360),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=120),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=71, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=360),\n",
            "    Message('note_on', channel=0, note=71, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=120),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=960),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=360),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=360),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=360),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=360),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=360),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=120),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=360),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=360),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=360),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=360),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=120),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=120),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=120),\n",
            "    Message('note_on', channel=0, note=71, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=120),\n",
            "    Message('note_on', channel=0, note=71, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=75, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=75, velocity=0, time=960),\n",
            "    Message('note_on', channel=0, note=75, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=960),\n",
            "    Message('note_on', channel=0, note=75, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=64, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=64, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=68, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=68, velocity=0, time=480),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=240),\n",
            "    Message('note_on', channel=0, note=71, velocity=80, time=0),\n",
            "    Message('note_on', channel=0, note=69, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=71, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=67, velocity=80, time=240),\n",
            "    Message('note_on', channel=0, note=69, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=80, time=480),\n",
            "    Message('note_on', channel=0, note=67, velocity=0, time=0),\n",
            "    Message('note_on', channel=0, note=66, velocity=0, time=480),\n",
            "    MetaMessage('end_of_track', time=1)])\n",
            "])\n"
          ]
        }
      ],
      "source": [
        "# Adapted from tutorial: https://www.twilio.com/blog/working-with-midi-data-in-python-using-mido\n",
        "mido_mid = MidiFile(local_datapath_midi, clip=True)\n",
        "print(mido_mid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MIDI File Header\n",
        "\n",
        "Let's start by looking at the header of the MIDI file which is included as attributes in the `mido` file object printed above. We will ignore the `tracks` for now, and revisit that in the next section. In particular, \n",
        "\n",
        "```python\n",
        "MidiFile(type=1, ticks_per_beat=480, tracks=[\n",
        "  MidiTrack([\n",
        "    MetaMessage('set_tempo', tempo=631579, time=0),...\n",
        "```\n",
        "\n",
        "`type` indicates the format of the MIDI file as discussed above (i.e. 0,1,2), `ticks_per_beat` indicates the number of ticks per beat (i.e. the resolution of the MIDI file) and `tracks` is a list of `MidiTrack` objects. The header byte info contains the number of tracks, though when interpreted by `mido` that is consolidated into the `tracks` variable. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Ticks \n",
        "Time in MIDI messages are all relative and associated with ticks. Ticks are the smallest unit of time in MIDI. The number of ticks per quarter note is defined in the header of the MIDI file (`480` for our file). Ticks are important becasue they are how time is denoted in MIDI messages. In particular, `time` is denoted in the number of ticks *after* the previous message to execute the action specified in the message. \n",
        "\n",
        "For example, if we have the following two messages:\n",
        "```python\n",
        "Message('note_on', channel=0, note=64, velocity=80, time=0),\n",
        "Message('note_on', channel=0, note=64, velocity=0, time=480)\n",
        "```\n",
        "\n",
        "The second message will be executed `480` ticks after the first message and in this case the note at pitch `64` will be turned off (since the velocity is `0`) after 480 ticks or 1 quarter note. A `time` of `0` indicates the message should be executed immediately or simulataneously with the previous message. For future reference, for `mido` file objects you can use the `ticks_per_beat` to get the number of ticks per quarter note. Later we can use this to convert to seconds once we know the tempo of the song."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "480\n"
          ]
        }
      ],
      "source": [
        "print(mido_mid.ticks_per_beat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBkrjlgfapjg"
      },
      "source": [
        "### Tracks\n",
        "\n",
        "A MIDI file can have multiple tracks like ours. The `MidiTrack` is a list of messages, which can be meta (i.e. related to metadata) or musical messages. `MetaMessage`'s have their own format, but do have a `type` which determines the other attributes of the message. \n",
        "\n",
        "#### Meta Tracks\n",
        "\n",
        "Although our simple melody track has 1 track of notes, there are two in this MIDI file because the first includes only relevant metadata and no musical messages. Let's delve into the first `MidiTrack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBL0_z_Zbi_1",
        "outputId": "075d92eb-1dbb-4208-a4fb-6308f2cc90c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MetaMessage('set_tempo', tempo=631579, time=0)\n"
          ]
        }
      ],
      "source": [
        "print(mido_mid.tracks[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2czw-rUbqG_"
      },
      "source": [
        "This is a starting messages or Meta message which occurs simultaneously with a previous event - i.e. `time=0` (of which there is none) that sets the tempo at 631579 microseconds / quarter note. This translates to 60000000/631579 ~ 95 quarter notes per minute or equivalently 95 BPM (beats per minute). Many of the meta messages have `time=0` since time is irrelevant, though we'll go over an exception next. \n",
        "\n",
        "With this tempo information we can now relate ticks to seconds. `480` ticks = 1 quarter note = 631579 microseconds = 0.631579 seconds => 1 tick = 0.0013158 seconds => ~45600 ticks / minute. While musicians often ignore this while composing or creating (i.e. beats matter more than time), this is useful to keep track of when converting this to audio or other formats. More info about the relationship between BPM (beats per minute), PPQN, MIDI Clock and SMPTE (time) can be found here:  http://midi.teragonaudio.com/tech/midifile/ppqn.htm\n",
        "\n",
        "Messages follow these and can have many actions, a full list can be found by the MIDI association: https://www.midi.org/specifications-old/item/table-1-summary-of-midi-message. Let's look at the next two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZChgBW3bzMl",
        "outputId": "92d3e960-f2da-439c-bac4-8800e4d51522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
            "MetaMessage('key_signature', key='E', time=0)\n"
          ]
        }
      ],
      "source": [
        "print(mido_mid.tracks[0][1])\n",
        "print(mido_mid.tracks[0][2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Time signature is a meta message that sets the time signature of the song. In this case, the time signature is 4/4 meaning 4 beats (numerator) of quarter (1/4) notes (denominator). \n",
        "\n",
        "The next message is a key signature message signifying E major. While this doesn't affect reading the file, when transposing a track in a Digital Audio Workstation it is helpful to know this. For example, if I were transposing the track to F major, I would need to transpose the notes up by 1 semitone (aka half step). Let's move on to the next one. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MetaMessage('marker', text='4_4_m_5_', time=0)\n"
          ]
        }
      ],
      "source": [
        "print(mido_mid.tracks[0][3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i66vIop0dAMl"
      },
      "source": [
        "This meta message is a \"marker\" message which marks a point in the track with some string or `text` for some duration (much like a note). and has a text of \"4_4_m_5_\". If we look a few messages down we'll see a message `MetaMessage('marker', text='4_4_m_5_', time=960)` which is a similar marker executed 960 ticks or 2 quarter notes after the previous message `MetaMessage('marker', text='11_11__5_', time=960)`. Although I'm not sure what the text indicates here, it can be used to distinguish \"verse\" from \"chorus\" or \"bridge\" sections, or can be used to indicate a change in emotion, whatever the author wants. Either way, these WILL NOT affect the actual music. Next let's move on to the actual music in the next track! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Musical Tracks\n",
        "\n",
        "Musical tracks will include mostly musical messages, but also will include some metadata. Let's look at the first meta message in the second `MidiTrack`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vek75hhrcvg3",
        "outputId": "07471a54-e577-4fe4-bab2-b9319cbcac19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MetaMessage('track_name', name='melody', time=0)\n"
          ]
        }
      ],
      "source": [
        "print(mido_mid.tracks[1][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This really doesn't do much except assign a name to the track, note it also defaults to `time=0` since it has no concept of time. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "program_change channel=0 program=0 time=0\n"
          ]
        }
      ],
      "source": [
        "print(mido_mid.tracks[1][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next is a `program_change` message indicates a change to `program=0` which might be a program for a MIDI instrument specified by `channel=0` (e.g. changing octaves for a synth). In our case, this doesn't do much.  Let's move on to the actual notes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1uc6XHTdL6x"
      },
      "source": [
        "Each `Message` has a `type`, `time`, `note`, `velocity` and `channel`. The `type` indicates the action to be taken. The `time` is the number of ticks since the last message. The `note` is the index of the pitch from 0-127. `velocity` is the volume with which the note is played from 0-127. `channel` is the instrument to which it is routed.\n",
        "\n",
        "Here are some more details: \n",
        "* `type` can be `note_on`, `note_off`, `control_change`, `program_change`, `pitchwheel`, `sysex` or `unknown`. More details can be found here: https://www.midi.org/specifications-old/item/table-1-summary-of-midi-message\n",
        "* `time` is an integer value called \"tick\" to synchronize the notes across tracks. To convert this to seconds or milliseconds, we can use the `ticks_per_beat` to convert to beats and then use tempo to convert it to seconds as we did above.\n",
        "* `note` is a range from 0 to 127 where each integer corresponds to a note and frequency: [full table here](https://www.inspiredacoustics.com/en/MIDI_note_numbers_and_center_frequencies). \n",
        "* `velocity` is a range from 0 to 127 representing the amplitude or volume of note played (0 - silence, 127 - loudest).\n",
        "* `channel` can be used to play multiple instruments at the same time (i.e. have multiple messages with different channels). In this case it is a simple melody piece so only 1 channel. For example, if we wanted to have a piano and a guitar playing at the same time, we could have two tracks with different `channel`'s and the same `time` and they would be played simultaneously. \n",
        "\n",
        "Let's take a look at a couple of these messages and interpret them. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "note_on channel=0 note=64 velocity=80 time=0\n",
            "note_on channel=0 note=64 velocity=0 time=480\n"
          ]
        }
      ],
      "source": [
        "print(mido_mid.tracks[1][2])\n",
        "print(mido_mid.tracks[1][3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first two messages correspond to a \"start\" / \"end\" of the first quarter note. Rather than using a `note_off` message, this uses two `note_on` of the same pitch 64 (E3) but offset by 480 ticks (1 quarter note) with velocity 80 for the first to trigger the note and to trigger the note to be silent after 1 quarter note. A `note_on` message with velocity 0 is equivalent to a `note_off` message. This entire melody uses all `note_on` messages, but using the `note_off` message is also common."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUEqtfdjb7Id"
      },
      "source": [
        "## MIDI Models and Input Formats\n",
        "\n",
        "If we look at some of the core papers looking at MIDI generation there bave been a number in the past few years - I won't try to be completely comprehensive here but I will note some of the important ones. The most notable ones in ~chronological order are (and coincidently though unsurprisingly grouped by models which correspond to the most popular types of models at the time): \n",
        "\n",
        "RNN-Based\n",
        "* MelodyRNN [Google Magenta] (Jul 2016) : LSTM based model for MIDI inputs\n",
        "  * Derivatives: DrumsRNN, ImprovRNN, PerformanceRNN, MusicRNN\n",
        "* DeepBach (Dec 2016): a Steerable Model for Bach Chorales Generation \n",
        "\n",
        "GAN-Based\n",
        "* MidiNet (Mar 2017) : Convolutional GAN-based sequential prediction of MIDI nodes with conditioning options for chord sequences and melody of previous bars\n",
        "* MuseGAN (~2017) : GAN-based model for generating multi-track MIDI files\n",
        "\n",
        "VAE-Based\n",
        "* MusicVAE [Google Magenta] (Mar 2018): Interpolate between two 16 bar midi notes for smoothness, realism and expression \n",
        "  * Derivatives: GrooVAE\n",
        "\n",
        "Transformer-Based\n",
        "* Music Transformer [Google Magenta] (Dec 2018) : Transformer-based model for generating multi-track MIDI files\n",
        "* MuseNet (2019) : GPT-2 based model for generating multi-track MIDI files\n",
        "\n",
        "Most importantly, they all use some form of a sequence as an input for training and inference. What we'll focus on first, is the question: **what format do these models expect the input to be in?** \n",
        "\n",
        "**NOTE: We are explicitly ignoring the question of preprocessing datasets (i.e. what format do datasets come in and how to transform them), which we will defer to the next post since it is important for training these sequence models above or creating our own to craft a training set which may include multiple sources that need to be standardized to a single input format. For now, we assume we have a MIDI file present as above and convert them to a format usable for training. We will also defer augmentation and other adjustments (e.g. transposition, tempo adjustments, etc.) to the next post where we'll discuss considerations for training the models.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypianoroll in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (1.0.4)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pypianoroll) (3.6.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pypianoroll) (1.24.3)\n",
            "Requirement already satisfied: pretty-midi>=0.2.8 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pypianoroll) (0.2.10)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pypianoroll) (1.10.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=1.5->pypianoroll) (9.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=1.5->pypianoroll) (1.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=1.5->pypianoroll) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=1.5->pypianoroll) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=1.5->pypianoroll) (4.25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=1.5->pypianoroll) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=1.5->pypianoroll) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=1.5->pypianoroll) (2.8.2)\n",
            "Requirement already satisfied: mido>=1.1.16 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pretty-midi>=0.2.8->pypianoroll) (1.3.0)\n",
            "Requirement already satisfied: six in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pretty-midi>=0.2.8->pypianoroll) (1.16.0)\n",
            "Requirement already satisfied: pretty_midi in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (0.2.10)\n",
            "Requirement already satisfied: six in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pretty_midi) (1.24.3)\n",
            "Requirement already satisfied: mido>=1.1.16 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from pretty_midi) (1.3.0)\n",
            "Requirement already satisfied: packaging~=23.1 in /Users/anand/opt/anaconda3/lib/python3.9/site-packages (from mido>=1.1.16->pretty_midi) (23.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypianoroll\n",
        "!pip install pretty_midi\n",
        "\n",
        "import pypianoroll\n",
        "import pretty_midi\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Piano Roll Representations\n",
        "\n",
        "The piano roll representation is a common way to represent music data.\n",
        "It consists of a two-dimensional matrix where the rows represent time steps\n",
        "and the columns represent pitches (and special symbols in certain variations). The entries of the matrix are often non-negative. \n",
        "\n",
        "One example is when the entries are binary, indicating whether a note is played at a given time step and pitch. \n",
        "\n",
        "X ∈ {0, 1}^(h×w) where `h` is the number of pitches and `w` is the number of time steps.\n",
        "\n",
        "*NOTE: velocity and complex time signature differences are IGNORED in this version!*\n",
        "\n",
        "Another variation on this form also considers the velocity of the note. In this case, the entries are integers in the range of 0-127 indicating the velocity of the note played at a given time step and pitch.\n",
        "\n",
        "X ∈ [0,127]^(h×w)\n",
        "\n",
        "NOTE: The number of pitches in a MIDI file is 128, however the dimension of `h` may be reduced to narrow the range of notes to a specific instrument (e.g. 88 keys in a piano) or can be expanded to include silence or rests (e.g. 129/130 or 89/90). The time steps also depend on the model and level of granularity desired. For coherence, many models filter inputs to 4/4 time signatures and use sixteenth notes as a single time step (16 steps / bar).  \n",
        "\n",
        "For the RNN-Based, GAN-Based and VAE-Based models above, at some level all of these look at splitting the MIDI files into discrete time bars and ignoring the velocity. However they vary in how they split the bars and the granularity of notes they use. \n",
        "\n",
        "***RNN-Based***\n",
        "* **MelodyRNN**: \"[60, -2, 60, -2, 67, -2, 67, -2]” (-2 = no event, -1=note-off event, 0-127 = note-on event for that MIDI pitch) for each track. 4/4 time signature with 16th notes as a single time step. Each bar has 16 time steps. Samples can be 2 bars or 16 bars. \n",
        "* **DeepBach**: 4 tracks/rows (soprano, alto, tenor, bass) with 16 time steps per bar (16th notes) represented by strings for the 128 pitches `C1` to `G9` and a hold `__` (i.e. 129 total pitches), two additional rows are added with `0` or `1` to indicate fermata and the beat count (e.g. `1,2,3,4`)\n",
        "\n",
        "***GAN-Based***\n",
        "* **MidiNet**: piano roll representation in 4/4 time signature with 16th notes as a single time step. Each track is a new channel (e.g. CxHxW). Each sample is 1 bar and each value can be one of 128 MIDI pitches or silence resulting in a Cx129x16 matrix for each bar. \n",
        "* **MuseGAN**: piano roll representation in 4/4 time signature with 16th notes as 6 time steps. That is each bar has 96 time steps. Each track is a new channel and each sample is 1 bar (e.g. CxHxW). Each value can be one of 128 MIDI pitches resulting in Cx128x96 matrix for each bar. The dimensions are rearranged to be 96x128xC. \n",
        "\n",
        "***VAE-Based***\n",
        "* **MusicVAE**: \"[60, -2, 60, -2, 67, -2, 67, -2]” (-2 = no event, -1=note-off event, 0-127 = note-on event for that MIDI pitch) for each track. 4/4 time signature with 16th notes as a single time step. Each bar has 16 time steps. Samples can be 2 bars or 16 bars. \n",
        "\n",
        "Observations: \n",
        "* All of these models use 4/4 time signature and a 16th note or some subset of them as a time step. This is likely because it helps with standardization and structure of the data. For examples if we processed 6/8 or 5/4 time signatures and split them with the same time steps as 4/4, we would capture motifs that span bars which may not be consistent. And since the majority of pieces are 4/4, it is advantageous to use that time signature and discard others. \n",
        "* All representations discard the velocity of the notes. This is likely because it is not as important for the melody and the models then not as sensitive to it, that is, there is less to learn. Velocity variations could also be added posthoc to make the outputs seem more realistic. \n",
        "* Representations of the matrix are still highly variable and depends on the model, the DL library (TF, Pytorch, etc) and the application. We'll next explore code to transform midi files to all of these formats. For the above models we'll focus on the following 3 common formats which were most common: \n",
        "   1. Compressed Piano Roll Representation w/ Pitch Indices (CxW): MelodyRNN, MusicVAE\n",
        "   2. Compressed Piano Roll Representation w/ Note Names (CxW): DeepBach\n",
        "   3. One/Multi-Hot Piano Roll Representations (CxHxW): MidiNet, MuseGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Compressed Piano Roll Representation w/ Pitch Indices (CxW)\n",
        "\n",
        "These representations are used commonly by the Google Magenta team across MelodyRNN and MusicVAE and represent each time step with an absolute pitch index `0-127` rather than a 1-hot or multi-hot encoding. Since it is can only represent 1 note per time step, the channels or `C` dimention enable multiple instruments or notes to be represented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1680)\n",
            "[[64 64 64 64 64 64 64 64 64 64 64 64 64 64 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67 67 67 67 67 67 67 67 66 66 66 66 66 66 66 66 66 66\n",
            "  66 66 67 67 67 67 67 67 67 67 67 67 67 67 66 66 66 66 66 66 66 66 66 66\n",
            "  66 66  0  0  0  0  0  0  0  0  0  0  0  0 64 64 64 64 64 64 64 64 64 64\n",
            "  64 64 64 64 64 64 64 64 64 64 64 64 64 64 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67 67 67 67 67 67 67 67 66 66 66 66 66 66 66 66 66 66\n",
            "  66 66 67 67 67 67 67 67 67 67 67 67 67 67 66 66 66 66 66 66 66 66 66 66\n",
            "  66 66  0  0  0  0  0  0  0  0  0  0  0  0 64 64 64 64 64 64 64 64 64 64\n",
            "  64  0 64 64 64 64 64 64 64 64 64 64 64 64 68 68 68 68 68 68 68 68 68 68\n",
            "  68 68 68 68 68 68 68 68 68 68 68 68 68 68 69 69 69 69 69 69 69 69 69 69\n",
            "  69  0 69 69 69 69 69 69 69 69 69 69 69  0 71 71 71 71 71 71 71 71 71 71\n",
            "  71 71 71 71 71 71 71  0 69 69 69 69 69  0 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67 67 67 67 67 67 67 67 66 66 66 66 66 66 66 66 66 66\n",
            "  66 66 66 66 66 66 66 66 66 66 66 66 66 66  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0 64 64 64 64 64 64 64 64 64 64\n",
            "  64 64 64 64 64 64 64 64 64 64 64 64 64  0 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67  0 67 67 67 67 67  0 66 66 66 66 66 66 66 66 66 66\n",
            "  66  0 67 67 67 67 67 67 67 67 67 67 67  0 66 66 66 66 66 66 66 66 66 66\n",
            "  66  0  0  0  0  0  0  0  0  0  0  0  0  0 64 64 64 64 64 64 64 64 64 64\n",
            "  64 64 64 64 64 64 64 64 64 64 64 64 64  0 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67  0 67 67 67 67 67  0 66 66 66 66 66 66 66 66 66 66\n",
            "  66  0 67 67 67 67 67 67 67 67 67 67 67  0 66 66 66 66 66 66 66 66 66 66\n",
            "  66  0  0  0  0  0  0  0  0  0  0  0  0  0 64 64 64 64 64 64 64 64 64 64\n",
            "  64 64 64 64 64 64 64 64 64 64 64 64 64  0 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67 67 67 67 67 67 67  0 69 69 69 69 69 69 69 69 69 69\n",
            "  69 69 69 69 69 69 69 69 69 69 69 69 69  0 71 71 71 71 71 71 71 71 71 71\n",
            "  71 71 71 71 71 71 71 71 69 69 69 69 69 69 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67 67 67 67 67 67 67 67 66 66 66 66 66 66 66 66 66 66\n",
            "  66 66 66 66 66 66 66 66 66 66 66 66 66 66  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0 68 68 68 68 68 68 68 68 68 68\n",
            "  68  0 68 68 68 68 68 68 68 68 68 68 68 68 69 69 69 69 69 69 69 69 69 69\n",
            "  69 69 69 69 69 69 69 69 69 69 69 69 69 69 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67 67 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66\n",
            "  66 66  0  0  0  0  0  0  0  0  0  0  0  0 68 68 68 68 68 68 68 68 68 68\n",
            "  68  0 68 68 68 68 68 68 68 68 68 68 68 68 69 69 69 69 69 69 69 69 69 69\n",
            "  69 69 69 69 69 69 69 69 69 69 69 69 69 69 67 67 67 67 67 67 67 67 67 67\n",
            "  67 67 67 67 67 67 67 67 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66\n",
            "  66 66  0  0  0  0  0  0  0  0  0  0  0  0 68 68 68 68 68 68 68 68 68 68\n",
            "  68  0 68 68 68 68 68 68 68 68 68 68 68 68 69 69 69 69 69 69 69 69 69 69\n",
            "  69 69 69 69 69 69]]\n"
          ]
        }
      ],
      "source": [
        "def midi_to_pitch_pianoroll(midi_file:str, resolution:int=24, program_num:int=0):\n",
        "    ppr_mid = pypianoroll.read(midi_file, resolution=resolution)\n",
        "    num_tracks = len(ppr_mid.tracks)\n",
        "    # assume all tracks have the same # of time steps\n",
        "    time_steps = ppr_mid.tracks[0].pianoroll.shape[0] \n",
        "    result = np.zeros((num_tracks, time_steps),dtype=int)\n",
        "\n",
        "    for i in range(len(ppr_mid.tracks)):\n",
        "        for j in range(ppr_mid.tracks[i].pianoroll.shape[0]):\n",
        "            note_ind = np.argmax(ppr_mid.tracks[i].pianoroll[j,:])\n",
        "            result[i,j] = note_ind\n",
        "\n",
        "    return result\n",
        "    \n",
        "test = midi_to_pitch_pianoroll(local_datapath_midi)\n",
        "print(test.shape)\n",
        "print(test[:,10:1000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: we result in 1680 time steps for the 17.5 bars in the song. Each bar has 4 beats, so 70 beats altogether. 1680/70 = 24, meaning we have 24 time steps per beat. 24 is the defualt resolution for pypianoroll, but we can update that depending on the granularity desired. Since we use pypianoroll, we'll have the same time steps for subsequent representations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Compressed Piano Roll Representation w/ Note Names (CxW)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1680)\n",
            "[['E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'E4' 'E4' 'E4' 'E4'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'C-1' 'E4' 'E4'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'G#4' 'G#4' 'G#4'\n",
            "  'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4'\n",
            "  'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'A4' 'A4' 'A4'\n",
            "  'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'C-1' 'A4' 'A4' 'A4' 'A4' 'A4'\n",
            "  'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'C-1' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4'\n",
            "  'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'C-1' 'A4' 'A4' 'A4'\n",
            "  'A4' 'A4' 'C-1' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'E4'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'C-1' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'C-1' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'C-1' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'C-1' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'C-1' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4'\n",
            "  'C-1' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'C-1' 'G4' 'G4' 'G4' 'G4' 'G4' 'C-1' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'C-1' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'C-1' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'E4' 'E4' 'E4'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4'\n",
            "  'E4' 'E4' 'E4' 'E4' 'E4' 'E4' 'C-1' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'C-1' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4'\n",
            "  'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'C-1' 'B4'\n",
            "  'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4' 'B4'\n",
            "  'B4' 'B4' 'B4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4'\n",
            "  'G#4' 'G#4' 'G#4' 'G#4' 'C-1' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4'\n",
            "  'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4'\n",
            "  'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4'\n",
            "  'A4' 'A4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'G#4'\n",
            "  'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'C-1' 'G#4'\n",
            "  'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'A4'\n",
            "  'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4'\n",
            "  'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'G4' 'G4' 'G4' 'G4' 'G4'\n",
            "  'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'F#4'\n",
            "  'F#4' 'F#4' 'F#4' 'F#4' 'F#4' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'C-1'\n",
            "  'C-1' 'C-1' 'C-1' 'C-1' 'C-1' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4'\n",
            "  'G#4' 'G#4' 'G#4' 'G#4' 'C-1' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'G#4'\n",
            "  'G#4' 'G#4' 'G#4' 'G#4' 'G#4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4'\n",
            "  'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4' 'A4']]\n"
          ]
        }
      ],
      "source": [
        "def midi_to_note_pianoroll(midi_file:str, resolution:int=24, program_num:int=0):\n",
        "    ppr_mid = pypianoroll.read(midi_file, resolution=resolution)\n",
        "    num_tracks = len(ppr_mid.tracks)\n",
        "    # assume all tracks have the same # of time steps\n",
        "    time_steps = ppr_mid.tracks[0].pianoroll.shape[0] \n",
        "    result = []\n",
        "\n",
        "    for i in range(len(ppr_mid.tracks)):\n",
        "        track_vals = []\n",
        "        for j in range(ppr_mid.tracks[i].pianoroll.shape[0]):\n",
        "            note_ind = np.argmax(ppr_mid.tracks[i].pianoroll[j,:])\n",
        "            track_vals.append(pretty_midi.note_number_to_name(note_ind))\n",
        "        result.append(track_vals)\n",
        "\n",
        "    return np.array(result)\n",
        "    \n",
        "test = midi_to_note_pianoroll(local_datapath_midi)\n",
        "print(test.shape)\n",
        "print(test[:,10:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. One/Multi-Hot Piano Roll Representations (CxHxW)\n",
        "\n",
        "The one/multi-hot piano roll representation is the classic representation used by MidiNet and MuseGAN and ignore the velocity which means that the piano roll representation they adhere too is the binary one: X ∈ {0, 1}^(H×W). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here the output of the piano roll will be a matrix with 128 rows to signify the 128 different pitch levels (note a piano only has 88). The columns will be the time steps. The values will be 1 or 0 to signify whether the note is played or not as a one-hot encoding. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: 'piano-roll.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: 'piano-roll.png'"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: 'piano-roll.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: 'piano-roll.png'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from IPython.display import Image\n",
        "Image('piano-roll.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can define a simple function to convert a MIDI file to this simple format. We'll use the `pretty_midi` library to parse the MIDI file and then use the `pypianoroll` library to convert it to a piano roll representation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def midi_to_piano_roll(midi_path:str, resolution:int=24) -> np.ndarray:\n",
        "    \"\"\"Converts a MIDI file to a binary piano roll representation.\n",
        "    More info about args: https://salu133445.github.io/pypianoroll/doc.html#pypianoroll.from_pretty_midi\n",
        "\n",
        "    Args:\n",
        "      midi_path (str): Path to the MIDI file.\n",
        "      resolution (int): Number of ticks per beat (default: 24).\n",
        "\n",
        "    Returns:\n",
        "      np.ndarray: Binary piano roll representation of the MIDI file.\n",
        "\n",
        "    Usage: \n",
        "    > midi_to_piano_roll(midi_path, resolution=24)\n",
        "    \"\"\"\n",
        "    ppr_midi = pypianoroll.read(midi_path, resolution=resolution)\n",
        "    ppr_midi.binarize()\n",
        "    piano_roll = ppr_midi.tracks[0].pianoroll.astype(int)\n",
        "    piano_roll = np.swapaxes(piano_roll,0,1)\n",
        "    return piano_roll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 1680)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "pr = midi_to_piano_roll(local_datapath_midi,resolution=24)\n",
        "print(pr.shape)\n",
        "print(pr[:,900]) # only look at 1 1-hot vector for 1 time step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MIDI Encodings\n",
        "\n",
        "Following in the footsteps of recent language models, transformer based models has used MIDI encodings to represent the MIDI files. In particular, language modeling has often used byte-pair encodings (BPE) to represent words as a sequence of bytes. This is a great way to represent words because it allows for a variable length encoding of words and allows for the model to learn sub-word representations.\n",
        "\n",
        "Let's explore what the Transformer based models use to represent MIDI files.\n",
        "\n",
        "***Transformer-Based***\n",
        "* **Music Transformer (Google)**: Multiple formats for different datasets and experiments   \n",
        "  - JS Chorales Bach: (similar to DeepBach) uses the following sequence of 4 voices (soprano, alto, tenor, bass) in 4/4 time in sixteenth note increments\n",
        "    - ![bach chorales](images/music-transformer-bach-chorales.png)\n",
        "    - Inputs are serialized $S_1A_1T_1B_1S_2A_2T_2B_2$ and each token is represented as a one-hot vector → 128 x (WxC) where W is number of sixteenth notes and C is the number of channels - in this case 4 for each voice\n",
        "  - Piano E Competition Dataset: [Ref: https://arxiv.org/pdf/1808.03715.pdf] → Use a set of sequence events like the following.\n",
        "    - ![piano competition](images/music-transformer-sequence.png)\n",
        "    - Overall the total number of sequences are eventually represented as a sequence of 1-hot vectors representing each of the 388 possible events -> 388 x T where T is the the number of 10ms increments in the sample. This representation for the Piano competition dataset is discussed in section 6.1 of [this paper](https://link.springer.com/article/10.1007/s00521-018-3758-9).\n",
        "      - 128 `NOTE-ON` events: one for each of the 128 MIDI pitches. Each one starts a new note.\n",
        "      - 128 `NOTE-OFF` events: one for each of the 128 MIDI pitches. Each one releases a note.\n",
        "      - 100 `TIME-SHIFT` events: each one moves the time step forward by increments of 10 ms up to 1 s.\n",
        "      - 32 `VELOCITY` events: each one changes the velocity applied to all subsequent notes (until the next velocity event).\n",
        "* **MuseNet (OpenAI)**:  `bach piano_strings start tempo90 piano:v72:G1 piano:v72:G2 piano:v72:B4 piano:v72:D4 violin:v80:G4 piano:v72:G4 piano:v72:B5 piano:v72:D5 wait:12 piano:v0:B5 wait:5 piano:v72:D5 wait:12 piano:v0:D5 wait:4 piano:v0:G1 piano:v0:G2 piano:v0:B4 piano:v0:D4 violin:v0:G4 piano:v0:G4 wait:1 piano:v72:G5 wait:12 piano:v0:G5 wait:5 piano:v72:D5 wait:12 piano:v0:D5 wait:5 piano:v72:B5 wait:12`\n",
        "\n",
        "Observations:\n",
        "* Transformer-based model representations are more flexible and leverage expressivity (velocity) and polyphonicity. \n",
        "* Transformer-based model representations only require sequential processing but are open to using one-hot vectors (i.e. pianoroll representations) as well as language based ones (i.e. MuseNet).\n",
        "* Representations can be broken down in the following ways:\n",
        "  1.  One-hot Binary Piano Roll Representations (128x(WxC)): Music Transformer (JS Chorales Bach)\n",
        "  2.  One-hot Expressive Piano Roll Representations (388xW): Music Transformer (Piano E Competition)\n",
        "  3.  Sequential Encoding & Tokenization (???): MuseNet "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. One-hot Binary Piano Roll Representations (128x(WxC))\n",
        "\n",
        "This is not too dissimilar from our previous work on representations except that it allows for combining the channels from different instruments into 1 dimension which means that W (the time dimension) and C (the channel dimension) are combined. It also means that an encoder and decoder must be present to identify these differences. Given we only have 1 track, the output will not be any different for our trial MIDI file, however we define a function that would work for multiple tracks. Our second dimention is WxC (in our case 1680x1=1680)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 1680)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "def midi_to_binary_pianoroll_multi_flat(midi_file:str, resolution:int=24):\n",
        "    ppr_mid = pypianoroll.read(midi_file, resolution=resolution)\n",
        "    num_tracks = len(ppr_mid.tracks)\n",
        "    # assume all tracks have the same # of time steps\n",
        "    time_steps = ppr_mid.tracks[0].pianoroll.shape[0] # W \n",
        "    result = np.zeros((num_tracks*time_steps, 128),dtype=int) # (CxW, H)\n",
        "    for time_id in range(time_steps):\n",
        "        for track_id in range(num_tracks):\n",
        "            if ppr_mid.tracks[track_id].pianoroll[time_id,:].any():\n",
        "                note_ind = np.argmax(ppr_mid.tracks[track_id].pianoroll[time_id,:])\n",
        "                result[(time_id*num_tracks) + track_id, note_ind] = 1\n",
        "    result = np.swapaxes(result,0,1)\n",
        "    return result\n",
        "\n",
        "result = midi_to_binary_pianoroll_multi_flat(local_datapath_midi)\n",
        "print(result.shape)\n",
        "print(result[:,900])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. One-hot Expressive Representation (388xW) - 1 Track\n",
        "\n",
        "This is a unique approach because it takes into account timing and velocity. It is also a one-hot representation, but it is not a piano roll representation. Instead it is a sequence of events that are encoded as one-hot vectors. To recap, the events we care about are: \n",
        "- 128 `NOTE-ON` events: one for each of the 128 MIDI pitches. Each one starts a new note.\n",
        "- 128 `NOTE-OFF` events: one for each of the 128 MIDI pitches. Each one releases a note. `NOTE-ON` with velocity 0 is equivalent to `NOTE-OFF`.\n",
        "- 100 `TIME-SHIFT` events: each one moves the time step forward by increments of 10 ms up to 1 s.\n",
        "- 32 `VELOCITY` events: each one changes the velocity applied to all subsequent notes (until the next velocity event).\n",
        "\n",
        "Our MIDI file is fairly standard in that it has just 1 velocity across all monophonic notes. Therefore, we will see very standard representations for this. However, if we had a more expressive MIDI file with multiple instruments and velocities, we would see more `VELOCITY` events. You might have noticed that we could add more events here to the vocabulary to expand the 1-hot representation to include other musical events like `TEMPO` or `KEY_SIGNATURE` or `TIME_SIGNATURE` or `PROGRAM_CHANGE` or `CONTROL_CHANGE` (e.g. pedal, levers,etc.) or `PITCH_WHEEL`, etc. However, we'll leave that for a future post. These are the events used in Musical Transformer.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(388, 281)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "import mido\n",
        "\n",
        "def midi_to_expressive_rep(midi_file:str):\n",
        "    \"\"\"Converts a MIDI file to an expanded representation. Assume 1 track\"\"\"\n",
        "    # USE MIDO to convert these to a list of note onsets and offsets\n",
        "    mido_mid = MidiFile(midi_file, clip=True)\n",
        "    tempo = mido_mid.tracks[0][0].tempo\n",
        "    ticks_per_beat = mido_mid.ticks_per_beat\n",
        "    curr_velocity = 0\n",
        "    # assume we use the 388 different representations from Music Transformer\n",
        "    result = np.empty([0,388])\n",
        "\n",
        "    for msg in mido_mid.tracks[1]:\n",
        "        if msg.type == 'note_on' or msg.type == 'note_off':\n",
        "            note_ind = msg.note\n",
        "            note_time = msg.time\n",
        "            note_velocity = msg.velocity\n",
        "            if note_time > 0: \n",
        "                del_t_sec = mido.tick2second(note_time, ticks_per_beat, tempo)\n",
        "                del_t_ms = del_t_sec*1000\n",
        "                time_ind = round(del_t_ms/10)\n",
        "                if time_ind > 99: # if the time step is greater than 100 ms, set it to 100 ms\n",
        "                    # add extra time step \n",
        "                    new_step = np.zeros((1,388))\n",
        "                    new_step[0,256+99] = 1 # set max time\n",
        "                    result = np.append(result, new_step, axis=0)\n",
        "                    # set time_ind to remainder \n",
        "                    time_ind = 100-time_ind \n",
        "                # add the time step\n",
        "                new_step = np.zeros((1,388))\n",
        "                new_step[0,256+time_ind] = 1 # set time\n",
        "                result = np.append(result, new_step, axis=0)\n",
        "        if msg.type == 'note_on' and msg.velocity > 0:\n",
        "            note_ind = msg.note\n",
        "            note_time = msg.time\n",
        "            note_velocity = msg.velocity\n",
        "            if note_velocity != curr_velocity:\n",
        "                # add set velocity \n",
        "                new_step = np.zeros((1,388))\n",
        "                velocity_ind = round((float(note_velocity)/128)*32)\n",
        "                new_step[0,356+velocity_ind] = 1 # set velocity\n",
        "                result = np.append(result, new_step, axis=0)\n",
        "                # update the curr_velocity\n",
        "                curr_velocity = note_velocity \n",
        "            # add the note on \n",
        "            new_step = np.zeros((1,388))\n",
        "            new_step[0,note_ind] = 1\n",
        "            result = np.append(result, new_step, axis=0)\n",
        "        if msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
        "            # add the note off message\n",
        "            new_step = np.zeros((1,388))\n",
        "            new_step[0,128+note_ind] = 1\n",
        "            result = np.append(result, new_step, axis=0) \n",
        "    result = np.swapaxes(result,0,1)\n",
        "    return result \n",
        "\n",
        "result = midi_to_expressive_rep(local_datapath_midi)\n",
        "print(result.shape)\n",
        "print(result[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Sequential Encoding & Tokenization (???)\n",
        "\n",
        "While MuseNet was one of the most interesting applications of MIDI-based music generation using GPT-2 and Sparse Transformers, the [blog post](https://openai.com/research/musenet) was \"sparse\" in its explanation of the encoding. Since the tokens were not explained I am not entirely sure how to convert the language sequence provided to discrete tokens to train a model (e.g. byte-pair encoding). We'll use some combination of expressive representations in 2 and 3 to train our own transformer-based model in a future post. \n",
        "\n",
        "For now, we'll write some code to convert a MIDI file to a format similar to the one mentioned in their blog post - all timings in ticks and all notes in MIDI pitch values.: \n",
        "\n",
        "`bach piano_strings start tempo90 piano:v72:G1 piano:v72:G2 piano:v72:B4 piano:v72:D4 violin:v80:G4 piano:v72:G4 piano:v72:B5 piano:v72:D5 wait:12 piano:v0:B5 wait:5 piano:v72:D5 wait:12 piano:v0:D5 wait:4 piano:v0:G1 piano:v0:G2 piano:v0:B4 piano:v0:D4 violin:v0:G4 piano:v0:G4 wait:1 piano:v72:G5 wait:12 piano:v0:G5 wait:5 piano:v72:D5 wait:12 piano:v0:D5 wait:5 piano:v72:B5 wait:12`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def midi_to_sequence(midi_file:str): \n",
        "    \"\"\"Converts a MIDI file a sequence. Assume 1 track\"\"\"\n",
        "    # USE MIDO to convert these to a list of note onsets and offsets\n",
        "    mido_mid = MidiFile(midi_file, clip=True)\n",
        "    tempo = mido_mid.tracks[0][0].tempo # assume tempo same for all tracks\n",
        "    tempo = round(mido.tempo2bpm(tempo)) # convert to bpm\n",
        "    instrument = \"piano\"\n",
        "    # assume we use the 388 different representations from Music Transformer\n",
        "    result = \"\"\n",
        "    result += mido_mid.tracks[1].name # add track name \n",
        "    result += \" \" + instrument # add instrument\n",
        "    result += \" start\" # add start token\n",
        "    result += \" tempo\" + str(tempo) # add tempo\n",
        "\n",
        "    # loop through track and add in the notes\n",
        "    for msg in mido_mid.tracks[1]:\n",
        "        if msg.type == 'note_on' or msg.type == 'note_off':\n",
        "            note_ind = msg.note\n",
        "            note_time = msg.time\n",
        "            note_velocity = msg.velocity\n",
        "            # add wait time before note \n",
        "            if note_time > 0: \n",
        "                result += \" wait:\" + str(note_time)\n",
        "            # add the note \n",
        "            result += \" \" + instrument + \":v\" + str(note_velocity) + \":\" + pretty_midi.note_number_to_name(note_ind)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "melody piano start tempo95 piano:v80:E4 wait:480 piano:v0:E4 piano:v80:G4 wait:480 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 piano:v80:G4 wait:240 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 wait:240 piano:v80:E4 wait:480 piano:v0:E4 piano:v80:G4 wait:480 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 piano:v80:G4 wait:240 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 wait:240 piano:v80:E4 wait:240 piano:v0:E4 piano:v80:E4 wait:240 piano:v0:E4 piano:v80:G#4 wait:480 piano:v0:G#4 piano:v80:A4 wait:240 piano:v0:A4 piano:v80:A4 wait:240 piano:v0:A4 piano:v80:B4 wait:360 piano:v80:A4 piano:v0:B4 wait:120 piano:v80:G4 piano:v0:A4 wait:480 piano:v80:F#4 piano:v0:G4 wait:480 piano:v0:F#4 wait:960 piano:v80:E4 wait:480 piano:v0:E4 piano:v80:G4 wait:360 piano:v0:G4 piano:v80:G4 wait:120 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 piano:v80:G4 wait:240 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 wait:240 piano:v80:E4 wait:480 piano:v0:E4 piano:v80:G4 wait:360 piano:v0:G4 piano:v80:G4 wait:120 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 piano:v80:G4 wait:240 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 wait:240 piano:v80:E4 wait:480 piano:v0:E4 piano:v80:G4 wait:480 piano:v0:G4 piano:v80:A4 wait:480 piano:v0:A4 piano:v80:B4 wait:360 piano:v80:A4 piano:v0:B4 wait:120 piano:v80:G4 piano:v0:A4 wait:480 piano:v80:F#4 piano:v0:G4 wait:480 piano:v0:F#4 wait:960 piano:v80:G#4 wait:240 piano:v0:G#4 piano:v80:G#4 wait:240 piano:v0:G#4 piano:v80:A4 wait:480 piano:v80:G4 piano:v0:A4 wait:360 piano:v80:F#4 piano:v0:G4 wait:360 piano:v0:F#4 wait:240 piano:v80:G#4 wait:240 piano:v0:G#4 piano:v80:G#4 wait:240 piano:v0:G#4 piano:v80:A4 wait:480 piano:v80:G4 piano:v0:A4 wait:360 piano:v80:F#4 piano:v0:G4 wait:360 piano:v0:F#4 wait:240 piano:v80:G#4 wait:240 piano:v0:G#4 piano:v80:G#4 wait:240 piano:v0:G#4 piano:v80:A4 wait:360 piano:v0:A4 piano:v80:A4 wait:120 piano:v80:G4 piano:v0:A4 wait:360 piano:v80:F#4 piano:v0:G4 wait:360 piano:v0:F#4 wait:240 piano:v80:G#4 wait:240 piano:v0:G#4 piano:v80:G#4 wait:240 piano:v0:G#4 piano:v80:A4 wait:480 piano:v80:G4 piano:v0:A4 wait:360 piano:v80:F#4 piano:v0:G4 wait:360 piano:v0:F#4 wait:240 piano:v80:E4 wait:240 piano:v0:E4 piano:v80:F#4 wait:120 piano:v0:F#4 piano:v80:G4 wait:120 piano:v80:F#4 piano:v0:G4 wait:480 piano:v0:F#4 piano:v80:G4 wait:240 piano:v0:G4 piano:v80:A4 wait:120 piano:v0:A4 piano:v80:B4 wait:120 piano:v80:A4 piano:v0:B4 wait:480 piano:v0:A4 piano:v80:D#5 wait:960 piano:v0:D#5 piano:v80:D#5 wait:960 piano:v80:E4 piano:v0:D#5 wait:480 piano:v0:E4 piano:v80:G4 wait:480 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 piano:v80:G4 wait:240 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 wait:240 piano:v80:E4 wait:480 piano:v0:E4 piano:v80:G4 wait:480 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 piano:v80:G4 wait:240 piano:v80:F#4 piano:v0:G4 wait:240 piano:v0:F#4 wait:240 piano:v80:E4 wait:240 piano:v0:E4 piano:v80:E4 wait:240 piano:v0:E4 piano:v80:G#4 wait:480 piano:v0:G#4 piano:v80:A4 wait:240 piano:v0:A4 piano:v80:A4 wait:240 piano:v0:A4 piano:v80:B4 wait:240 piano:v80:A4 piano:v0:B4 wait:240 piano:v80:G4 piano:v0:A4 wait:480 piano:v80:F#4 piano:v0:G4 wait:480 piano:v0:F#4\n"
          ]
        }
      ],
      "source": [
        "result =  midi_to_sequence(local_datapath_midi)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions\n",
        "\n",
        "The transformer based models are the most recent and have shown to be the most expressive - the sequences used leverage velocity, polyphonicity and dynamics of MIDI instruments and have shown to better represent long term structure (unsurprising given similar results in language). \n",
        "\n",
        "We'll take a deeper dive into those because they are flexible and we can experiment with many of the latest architectures being used for language modeling. We can choose to use the same encodings as the models above or we can experiment with other encodings that express similar or even additional information. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMJ0zMvlrdPUi4VaBls//Lu",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
